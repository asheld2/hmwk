Generative Adversarial Networks are a type of artificial intelligence that can generate fake images that appear convincingly real. The idea of adversarial networks was half-conceptualized in the 1960s, but due to lack of resources, wasnâ€™t fully realized. Later on it was reinvented by Jurgen Schmidhuber in 1990. He came up with the idea of opposing neural networks, called Net 1 and Net 2. A recurrent neural network called Long Short Term Memory, or LSTM, was invented by Schmidhuber, and used for language-related AI functions such as voice recognition and Google translate. Then, in 2014, Ian Goodfellow with help from a team of other computer scientists further developed neural networks and coined the term General Adversarial Networks. In a similar vein to Net 1 and Net 2, GANs have two networks called a generator and discriminator. These engage in a zero-sum probability game: the generator produces an image, and the discriminator determines the probability that it looks like the real thing. A random noise signal is fed to the generator, which it transposes into pixels through a series of probability vectors. This is done through a p(y|x) (probability of y given x) type of function. For instance, the probability of producing a cat given that this image contains ears, or p(cat|ears). The discriminator then takes this generated image of a cat and compares it to multitudes of real images of cats (also using probability functions and 4 convolution layers). After assessing the fake image from the generator, the discriminator signals that either the image is convincing or unconvincing. Some GANs use Bayesian statistical inference (which updates a probability formula as more data becomes available.) Using a Bayesian GAN prevents mode collapse and better image results from GANs.
